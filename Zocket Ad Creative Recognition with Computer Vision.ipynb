{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3\n",
    "from keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './Train/Train_aug',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    './Val/Val_aug',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Construction and Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'optimizer': [tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  tf.keras.optimizers.RMSprop(learning_rate=0.0001)]\n",
    "}\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=0)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=StratifiedKFold(n_splits=3))\n",
    "grid_result = grid.fit(train_generator, steps_per_epoch=len(train_generator), validation_data=validation_generator, validation_steps=len(validation_generator))\n",
    "\n",
    "print(\"Best Optimizer:\", grid_result.best_params_['optimizer'])\n",
    "\n",
    "model = create_model(optimizer=grid_result.best_params_['optimizer'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_generator)\n",
    "\n",
    "model.save('ad_creative_detection_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Visualization Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Visualization Integration\n",
    "def analyze_features(model, img_path, layer_names):\n",
    "    # Load and preprocess the image\n",
    "    img = plt.imread(img_path)\n",
    "    img = tf.image.resize(img, [200, 200])\n",
    "    img_array = np.expand_dims(img, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    for layer_name in layer_names:\n",
    "        intermediate_layer_model = models.Model(inputs=model.input,\n",
    "                                                outputs=model.get_layer(layer_name).output)\n",
    "        intermediate_output = intermediate_layer_model.predict(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced False Positive Reduction Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, self.W)\n",
    "        x = tf.nn.tanh(x + self.b)\n",
    "        x = tf.nn.softmax(x, axis=1)\n",
    "        return x * inputs\n",
    "\n",
    "# Modify model to incorporate attention mechanism\n",
    "attention_model = models.Sequential([\n",
    "    base_model,\n",
    "    AttentionLayer(),\n",
    "    layers.Flatten(name='flatten'),\n",
    "    layers.Dense(512, activation='relu', name='dense'),\n",
    "    layers.Dense(1, activation='sigmoid', name='dense_1')\n",
    "])\n",
    "\n",
    "# Compile and train the attention model\n",
    "attention_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "attention_model.summary()\n",
    "\n",
    "history_attention = attention_model.fit(train_generator,\n",
    "                                        epochs=20,\n",
    "                                        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, generator):\n",
    "    y_true = generator.classes\n",
    "    y_pred = model.predict(generator)\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cr = classification_report(y_true, y_pred, target_names=generator.class_indices.keys())\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(cr)\n",
    "\n",
    "evaluate_model(model, validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plotting and Final Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "print(\"Final Validation Accuracy:\", final_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ad_creative(model, img_path):\n",
    "    test_img = Image.open(img_path)\n",
    "    test_img = test_img.resize((200, 200))  # Resize to match model input shape\n",
    "    test_img = np.array(test_img) / 255.0  # Normalize pixel values\n",
    "\n",
    "    # Perform prediction on the test image\n",
    "    prediction = model.predict(np.expand_dims(test_img, axis=0))\n",
    "\n",
    "    # Interpret prediction\n",
    "    class_labels = ['Non-Ad', 'Ad']\n",
    "    predicted_class = class_labels[int(np.round(prediction[0][0]))]\n",
    "    return predicted_class\n",
    "\n",
    "# Test the model with a sample image\n",
    "test_image_path = 'test_image.jpg'\n",
    "predicted_class = predict_ad_creative(model, test_image_path)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3\n",
    "from keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Data Loading and Preparation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './Train/Train_aug',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    './Val/Val_aug',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Model Construction and Compilation\n",
    "def create_model(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Hyperparameter Tuning with Cross-Validation\n",
    "param_grid = {\n",
    "    'optimizer': [tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  tf.keras.optimizers.RMSprop(learning_rate=0.0001)]\n",
    "}\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=0)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=StratifiedKFold(n_splits=3))\n",
    "grid_result = grid.fit(train_generator, steps_per_epoch=len(train_generator), validation_data=validation_generator, validation_steps=len(validation_generator))\n",
    "\n",
    "print(\"Best Optimizer:\", grid_result.best_params_['optimizer'])\n",
    "\n",
    "model = create_model(optimizer=grid_result.best_params_['optimizer'])\n",
    "model.summary()\n",
    "\n",
    "# Model Training\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_generator)\n",
    "\n",
    "model.save('ad_creative_detection_model.h5')\n",
    "\n",
    "# Feature Extraction and Analysis\n",
    "def extract_features(model, img_path):\n",
    "    img = plt.imread(img_path)\n",
    "    img = tf.image.resize(img, [200, 200])\n",
    "    img_array = np.expand_dims(img, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    intermediate_layer_model = models.Model(inputs=model.input,\n",
    "                                            outputs=model.get_layer('global_average_pooling2d').output)\n",
    "    features = intermediate_layer_model.predict(img_array)\n",
    "    return features\n",
    "\n",
    "# False Positive Reduction with Attention Mechanism\n",
    "class AttentionLayer(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, self.W)\n",
    "        x = tf.nn.tanh(x + self.b)\n",
    "        x = tf.nn.softmax(x, axis=1)\n",
    "        return x * inputs\n",
    "\n",
    "# Modify model to incorporate attention mechanism\n",
    "attention_model = models.Sequential([\n",
    "    base_model,\n",
    "    AttentionLayer(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and train the attention model\n",
    "attention_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "attention_model.summary()\n",
    "\n",
    "history_attention = attention_model.fit(train_generator,\n",
    "                                        epochs=20,\n",
    "                                        validation_data=validation_generator)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, generator):\n",
    "    y_true = generator.classes\n",
    "    y_pred = model.predict(generator)\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cr = classification_report(y_true, y_pred, target_names=generator.class_indices.keys())\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(cr)\n",
    "\n",
    "evaluate_model(model, validation_generator)\n",
    "\n",
    "# Plotting and Final Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "print(\"Final Validation Accuracy:\", final_val_accuracy)\n",
    "\n",
    "# Test Prediction\n",
    "def predict_ad_creative(model, img_path):\n",
    "    test_img = Image.open(img_path)\n",
    "    test_img = test_img.resize((200, 200))  # Resize to match model input shape\n",
    "    test_img = np.array(test_img) / 255.0  # Normalize pixel values\n",
    "\n",
    "    # Perform prediction on the test image\n",
    "    prediction = model.predict(np.expand_dims(test_img, axis=0))\n",
    "\n",
    "    # Interpret prediction\n",
    "    class_labels = ['Non-Ad', 'Ad']\n",
    "    predicted_class = class_labels[int(np.round(prediction[0][0]))]\n",
    "    return predicted_class\n",
    "\n",
    "# Test the model with a sample image\n",
    "test_image_path = 'test_image.jpg'\n",
    "predicted_class = predict_ad_creative(model, test_image_path)\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
